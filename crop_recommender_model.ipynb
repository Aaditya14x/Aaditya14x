{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUQcS15ckohdptRvGqen1X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashutosh7i/Aaditya14x/blob/main/crop_recommender_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task: Develop a simple recommendation system that suggests the best crops to plant based on soil properties such as pH, temperature, and humidity.\n",
        "\n",
        "Will make a web-app where farmer will enter-\n",
        "Temp, Humidity, ph, Rainfall of his area as (K,N,P) are hard to derive.\n",
        "\n",
        "App will suggest 3 crops to plant with images all in native language.\n",
        "\n",
        "Below is ML model with random forest algo."
      ],
      "metadata": {
        "id": "I0_o7L73eYTL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "kmbpSdPnZqxS"
      },
      "outputs": [],
      "source": [
        "# Step 1: Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load and explore data\n",
        "data = pd.read_csv('Crop_recommendation.csv')\n",
        "print(data.head())\n",
        "print(data.info())\n",
        "print(data.describe())\n",
        "\n",
        "print(data['label'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKPmXpmkezCc",
        "outputId": "09007a55-6a6c-470e-ff36-75ee6f609f1b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    N   P   K  temperature   humidity        ph    rainfall label\n",
            "0  90  42  43    20.879744  82.002744  6.502985  202.935536  rice\n",
            "1  85  58  41    21.770462  80.319644  7.038096  226.655537  rice\n",
            "2  60  55  44    23.004459  82.320763  7.840207  263.964248  rice\n",
            "3  74  35  40    26.491096  80.158363  6.980401  242.864034  rice\n",
            "4  78  42  42    20.130175  81.604873  7.628473  262.717340  rice\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2200 entries, 0 to 2199\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   N            2200 non-null   int64  \n",
            " 1   P            2200 non-null   int64  \n",
            " 2   K            2200 non-null   int64  \n",
            " 3   temperature  2200 non-null   float64\n",
            " 4   humidity     2200 non-null   float64\n",
            " 5   ph           2200 non-null   float64\n",
            " 6   rainfall     2200 non-null   float64\n",
            " 7   label        2200 non-null   object \n",
            "dtypes: float64(4), int64(3), object(1)\n",
            "memory usage: 137.6+ KB\n",
            "None\n",
            "                 N            P            K  temperature     humidity  \\\n",
            "count  2200.000000  2200.000000  2200.000000  2200.000000  2200.000000   \n",
            "mean     50.551818    53.362727    48.149091    25.616244    71.481779   \n",
            "std      36.917334    32.985883    50.647931     5.063749    22.263812   \n",
            "min       0.000000     5.000000     5.000000     8.825675    14.258040   \n",
            "25%      21.000000    28.000000    20.000000    22.769375    60.261953   \n",
            "50%      37.000000    51.000000    32.000000    25.598693    80.473146   \n",
            "75%      84.250000    68.000000    49.000000    28.561654    89.948771   \n",
            "max     140.000000   145.000000   205.000000    43.675493    99.981876   \n",
            "\n",
            "                ph     rainfall  \n",
            "count  2200.000000  2200.000000  \n",
            "mean      6.469480   103.463655  \n",
            "std       0.773938    54.958389  \n",
            "min       3.504752    20.211267  \n",
            "25%       5.971693    64.551686  \n",
            "50%       6.425045    94.867624  \n",
            "75%       6.923643   124.267508  \n",
            "max       9.935091   298.560117  \n",
            "['rice' 'maize' 'chickpea' 'kidneybeans' 'pigeonpeas' 'mothbeans'\n",
            " 'mungbean' 'blackgram' 'lentil' 'pomegranate' 'banana' 'mango' 'grapes'\n",
            " 'watermelon' 'muskmelon' 'apple' 'orange' 'papaya' 'coconut' 'cotton'\n",
            " 'jute' 'coffee']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Data preprocessing\n",
        "# Exclude N, P, and K from features\n",
        "X = data.drop(['N', 'P', 'K', 'label'], axis=1)\n",
        "y = data['label']"
      ],
      "metadata": {
        "id": "-BKEuzPRfIUQ"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "0tiCPCBNfJrk"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "dBkkEOgufLdt"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Model selection and training\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "hv3xF5OdfM8u",
        "outputId": "de123615-8b19-47fd-e6f5-39a78fd41fdd"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Model evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr99PYLUfOYn",
        "outputId": "2fca554a-94c5-4a9b-c578-ac159568aabb"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9636363636363636\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       apple       0.96      0.96      0.96        23\n",
            "      banana       1.00      1.00      1.00        21\n",
            "   blackgram       0.95      1.00      0.98        20\n",
            "    chickpea       1.00      1.00      1.00        26\n",
            "     coconut       1.00      1.00      1.00        27\n",
            "      coffee       0.94      1.00      0.97        17\n",
            "      cotton       1.00      1.00      1.00        17\n",
            "      grapes       1.00      1.00      1.00        14\n",
            "        jute       0.92      1.00      0.96        23\n",
            " kidneybeans       1.00      1.00      1.00        20\n",
            "      lentil       0.92      1.00      0.96        11\n",
            "       maize       0.91      1.00      0.95        21\n",
            "       mango       0.86      1.00      0.93        19\n",
            "   mothbeans       1.00      0.88      0.93        24\n",
            "    mungbean       1.00      0.95      0.97        19\n",
            "   muskmelon       1.00      1.00      1.00        17\n",
            "      orange       0.80      0.86      0.83        14\n",
            "      papaya       1.00      1.00      1.00        23\n",
            "  pigeonpeas       1.00      0.78      0.88        23\n",
            " pomegranate       0.95      0.91      0.93        23\n",
            "        rice       1.00      0.89      0.94        19\n",
            "  watermelon       0.95      1.00      0.97        19\n",
            "\n",
            "    accuracy                           0.96       440\n",
            "   macro avg       0.96      0.96      0.96       440\n",
            "weighted avg       0.97      0.96      0.96       440\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Prediction\n",
        "# Temp, Humidity, ph, Rainfall\n",
        "new_data = np.array([[25.05802193,84.97323747,5.738678895,110.4408803]])  # Input from frontend\n",
        "new_data_scaled = scaler.transform(new_data)\n",
        "probabilities = model.predict_proba(new_data_scaled)[0]\n",
        "\n",
        "# Get indices of top 3 probabilities\n",
        "top_indices = probabilities.argsort()[-3:][::-1]\n",
        "\n",
        "# Get corresponding crop labels\n",
        "top_crops = model.classes_[top_indices]\n",
        "print(\"Top 3 recommended crops:\", top_crops)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGPiAxg8fPmq",
        "outputId": "77e6807e-ae02-4805-dc5e-6ebcfc5d4db9"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 recommended crops: ['banana' 'pomegranate' 'grapes']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a H5 model"
      ],
      "metadata": {
        "id": "Mm42us040g4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from tensorflow import keras\n",
        "\n",
        "# Save the trained model as a pickle file\n",
        "joblib.dump(model, 'crop_recommendation_model.pkl')\n",
        "\n",
        "# Load the model from the pickle file\n",
        "model = joblib.load('crop_recommendation_model.pkl')\n",
        "\n",
        "# Convert the RandomForestClassifier to a keras model\n",
        "keras_model = keras.Sequential([\n",
        "    keras.layers.Input(shape=(X_train.shape[1],)),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(len(model.classes_), activation='softmax')\n",
        "])\n",
        "keras_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Transfer the weights from the RandomForestClassifier to the keras model\n",
        "for i, layer in enumerate(keras_model.layers):\n",
        "    if i == 0:  # Skip the input layer\n",
        "        continue\n",
        "    layer.set_weights([model.estimators_[i-1].feature_importances_])\n",
        "\n",
        "# Save the keras model as an h5 file\n",
        "keras_model.save('crop_recommendation_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "n6XKahNJq7or",
        "outputId": "a46128ef-0fe3-4953-b197-eaaa0fc69e8c"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "You called `set_weights(weights)` on layer \"dense_1\" with a weight list of length 1, but the layer was expecting 2 weights. Provided weights: [array([0.21939065, 0.37823331, 0.16500771, 0.2373...",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-6d69f69cb07e>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Skip the input layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Save the keras model as an h5 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpected_num_weights\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1797\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1798\u001b[0m                 \u001b[0;34m'You called `set_weights(weights)` on layer \"%s\" '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 \u001b[0;34m\"with a weight list of length %s, but the layer was \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You called `set_weights(weights)` on layer \"dense_1\" with a weight list of length 1, but the layer was expecting 2 weights. Provided weights: [array([0.21939065, 0.37823331, 0.16500771, 0.2373..."
          ]
        }
      ]
    }
  ]
}